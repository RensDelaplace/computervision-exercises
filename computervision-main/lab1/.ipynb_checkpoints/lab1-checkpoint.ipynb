{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefcef1f-effa-41ce-bc1b-0c8e5a2b9b56",
   "metadata": {},
   "source": [
    "# Computer Vision Lab 1 - Basic image operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db8f64d-3fce-44c9-af64-152642b8a4ad",
   "metadata": {},
   "source": [
    "Imports & name-adding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38239ef-5ce9-4ac6-823e-d5017e1c9b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "NAME = \"Rens Delaplace\"\n",
    "\n",
    "def add_name_to_image(image):\n",
    "    \"\"\"\n",
    "    Voeg de naam toe aan de afbeelding op een standaard positie (rechtsonder).\n",
    "    :param image: De afbeelding waarop de naam wordt toegevoegd.\n",
    "    :return: De afbeelding met de naam toegevoegd.\n",
    "    \"\"\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.6\n",
    "    thickness = 1\n",
    "    \n",
    "    # Bereken de grootte van de tekst\n",
    "    text_size = cv2.getTextSize(NAME, font, font_scale, thickness)[0]\n",
    "    \n",
    "    # Bepaal de positie rechtsonder\n",
    "    position = (image.shape[1] - text_size[0] - 10, image.shape[0] - 10)\n",
    "    \n",
    "    # Voeg de naam toe aan de afbeelding\n",
    "    cv2.putText(image, NAME, position, font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f60d7-cf9a-4a23-89d6-22a3f1263a18",
   "metadata": {},
   "source": [
    "## Reading, manipulating and writing pixel data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c4890-a7f6-4d46-9456-f1ebc867387c",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e52bfd-a244-4c0d-b099-9e47f5cc8175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: Height=360, Width=801, Channels=3\n"
     ]
    }
   ],
   "source": [
    "# Read the image\n",
    "image = cv2.imread(\"img/clouds.jpg\")\n",
    "\n",
    "# dimensions\n",
    "height, width, channels = image.shape\n",
    "print(f\"Image dimensions: Height={height}, Width={width}, Channels={channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ff3a5-9135-4994-97c1-689ce3917ae6",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a046b12a-5839-47ad-a12f-6e96d001e732",
   "metadata": {},
   "source": [
    "> What do the dimensions of the image array represent?\n",
    "\n",
    "They represent the hight, width and color channels of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b619e1-d971-4488-82d7-be1593929434",
   "metadata": {},
   "source": [
    "#### Assignment 1\n",
    "> Crop the image so it becomes square by chopping off the a part on the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd21c51-5c31-4c3a-a921-3f6796f4a350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_size = min(height, width)\n",
    "cropped_image = image[:, :square_size]\n",
    "\n",
    "cropped_image = add_name_to_image(cropped_image)\n",
    "cv2.imwrite('out/assignement1.jpg', cropped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a36fdc2-32cc-46d1-9955-857bf77791f8",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb93c34d-5484-4012-9ad7-c70872fb1774",
   "metadata": {},
   "source": [
    "#### Assignment 2\n",
    "> Discolor the image by reducing the intensity of the red value of every pixel by half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a5b8d9-dc13-4dff-ab39-4c9f3174586c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assignment 2: Reduce the red intensity by half\n",
    "red_reduced = image.copy()\n",
    "red_reduced[:, :, 2] = red_reduced[:, :, 2] // 2  # OpenCV uses BGR format\n",
    "red_reduced = add_name_to_image(red_reduced)\n",
    "cv2.imwrite('out/assignement2.jpg', red_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82c2b4a-0024-4e4b-a53f-4fe21761c75d",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e93a4-d7d6-4149-9c1e-72c3a355cb4a",
   "metadata": {},
   "source": [
    "#### Assignment 3\n",
    "> Discolor the image by doubling the intensity of the red value of every pixel. You may have\n",
    "to handle an overflow problem (and use two more lines of code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234e9792-f9fb-4646-8fe4-a73c7ad65329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_doubled = image.copy()\n",
    "red_doubled[:, :, 2] = np.clip(red_doubled[:, :, 2] * 2, 0, 255)\n",
    "\n",
    "red_doubled = add_name_to_image(red_doubled)\n",
    "cv2.imwrite('out/assignement3.jpg', red_doubled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9d1bd-aef0-4164-bba1-9b4b63a0bcad",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9fc5b5-fcf6-40a0-94ef-d92673ad0750",
   "metadata": {},
   "source": [
    "#### Assignment 4\n",
    "> Make a regular grid of black dots on the image so that the dots are 10 pixels apart vertically and horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7cfd26-81bc-4688-973b-74d6c6f199af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_image = image.copy()\n",
    "for y in range(0, height, 10):\n",
    "    for x in range(0, width, 10):\n",
    "        cv2.circle(grid_image, (x, y), 1, (0, 0, 0), -1)  # Black dot \n",
    "        # (grid_image → The image on which to draw\n",
    "        # (x, y) → The position of the center of the circle. \n",
    "        # 2 → Radius of the circle (2 pixels)\n",
    "        # (0, 0, 0) → Black color in BGR format.\n",
    "        # -1 → Fills the circle completely.\n",
    "        \n",
    "grid_image = add_name_to_image(grid_image)\n",
    "cv2.imwrite('out/assignement4.jpg', grid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a14454-7185-4c52-ad90-0a62e5f7b253",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12821fe-a29d-4b89-a305-e4d3c3fa3f7e",
   "metadata": {},
   "source": [
    "## Tresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce3cdd-6233-4ec8-87a5-cc8ec3fba0e1",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "#### Assignment 5 \n",
    "> Convert the image to a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b73021-8470-49b2-8014-b8407f114b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('img/clouds.jpg')\n",
    "grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "grayscale_image = add_name_to_image(grayscale_image)\n",
    "cv2.imwrite('out/assignement5.jpg', grayscale_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748ded96-ab7b-4156-8cf4-c0264ba28fdb",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28fa17-b46b-49cf-bfb6-18b8f3d43b59",
   "metadata": {},
   "source": [
    "#### Assignment 6 \n",
    "> Threshold the grayscale image at 50% of the maximum value for this datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a06ec42-039f-4581-a310-4c9f0aaedf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the maximum pixel value for the datatype\n",
    "max_value = np.iinfo(image.dtype).max\n",
    "threshold_value = max_value // 2  # 50% of max value\n",
    "\n",
    "_, thresholded_image = cv2.threshold(grayscale_image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "thresholded_image = add_name_to_image(thresholded_image)\n",
    "cv2.imwrite('out/assignement6.jpg', thresholded_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6713e11-9aca-4c16-8f98-dc8ca2baf0f6",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb9b0de-d29c-4313-b703-8721a9ce5d76",
   "metadata": {},
   "source": [
    "#### Assignment 7 \n",
    "> Threshold the grayscale image at the ideal threshold determined by Otsu’s method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20376df6-6610-47a9-bc06-e3b6857f4fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, otsu_thresholded_image = cv2.threshold(grayscale_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "otsu_thresholded_image = add_name_to_image(otsu_thresholded_image)\n",
    "cv2.imwrite('out/assignement7.jpg', otsu_thresholded_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f2bf0-df41-4247-a086-3949c700217f",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d6612-c582-4d8f-97b9-ac83ecbe6307",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "#### Assignment 8\n",
    "> Adaptively threshold the grayscale version of painting2.jpg so you get a similar result to the one below, where the background is uniformly white and you can cut out the painting along black lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1cb11da-e89c-4229-9dda-0e00236f966d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the image in grayscale\n",
    "painting_image = cv2.imread(\"img/painting2.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Ensure the image is in 8-bit format\n",
    "painting_image = cv2.convertScaleAbs(painting_image)\n",
    "\n",
    "adaptive_thresholded_image = cv2.adaptiveThreshold(painting_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "\n",
    "adaptive_thresholded_image = add_name_to_image(adaptive_thresholded_image)\n",
    "cv2.imwrite(\"out/assignement8.jpg\", adaptive_thresholded_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246cd5fd-b9a8-432b-a594-492e480e999c",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405ca67-d8c7-4ad6-a59c-26e8e2446aee",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a827f7-4b0d-4187-b0bc-86d3e09412a8",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "#### Assignment 9\n",
    "> Remove the white noise from whitenoise.png by Gaussian filtering. Find parameters for the Gaussian kernel that you find strike a good balance between noise level and blurriness of the result. This is subjective, but experiment with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a1a402-0021-4972-aa53-8c09426f87ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitenoise_image = cv2.imread('img/whitenoise.png')\n",
    "\n",
    "kernel_size = (7, 7)\n",
    "sigma = 4\n",
    "gaussian_filtered_image = cv2.GaussianBlur(whitenoise_image, kernel_size, sigma)\n",
    "\n",
    "gaussian_filtered_image = add_name_to_image(gaussian_filtered_image)\n",
    "cv2.imwrite('out/assignement9.jpg', gaussian_filtered_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9373b52-2048-449c-bfa8-3193fd4a456f",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement9.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d28f7c-80a9-418c-8e34-fda47d321b15",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "> Can you choose the kernel size and sigma of the distribution independent of each other?\n",
    "\n",
    "The kernel size (the size of the filter window) and sigma (the standard deviation of the Gaussian) are related.\n",
    "\n",
    "If the kernel size is too small relative to sigma, important parts of the Gaussian distribution will be cut off, reducing accuracy. If the kernel size is too large, it increases computation time without significantly improving the result. Kernel size is often chosen as a multiple of sigma, for example 3*sigma. A larger kernel size generally requires a larger sigma for effective smoothing. However, they can be adjusted independently to find the right balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ccc25-522f-439b-ba65-7a5f5bb38311",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "#### Assignment 10\n",
    "> Test the Gaussian filter on saltandpeppernoise.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fca7078-fc9b-46f7-b465-47eba77fd411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saltpeppernoise_image = cv2.imread('img/saltandpeppernoise.png')\n",
    "\n",
    "kernel_size = (7, 7)\n",
    "sigma = 4\n",
    "gaussian_filtered_image = cv2.GaussianBlur(saltpeppernoise_image, kernel_size, sigma)\n",
    "\n",
    "gaussian_filtered_image = add_name_to_image(gaussian_filtered_image)\n",
    "cv2.imwrite('out/assignement10.jpg', gaussian_filtered_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e6f34c-2dd3-4fd7-ae67-9448d702b022",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15aa2c-a47c-4df1-b8ad-e618b7f3303b",
   "metadata": {},
   "source": [
    "#### Assignment 11\n",
    "> Apply median filtering on the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b80a94b4-4380-49c5-a472-dc21137cd605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saltpeppernoise_image = cv2.imread('img/saltandpeppernoise.png')\n",
    "median_filtered_image = cv2.medianBlur(saltpeppernoise_image, 5)\n",
    "\n",
    "median_filtered_image = add_name_to_image(median_filtered_image)\n",
    "cv2.imwrite('out/assignement11.jpg', median_filtered_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70075754-4ab6-41bf-8e0a-147b63e8022c",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement11.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b0d36-9590-438c-9956-c4566973687f",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "> Which result is preferable and why?\n",
    "\n",
    "Median filtering is prefered for images with salt and pepper noise, as it discards outliers (salt & peper), while median filtering mixes these values with the rest of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce7a62-b38b-4fba-9067-d4621969c5bc",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "#### Assignment 12\n",
    "> Implement unsharp masking to sharpen unsharp.png. Make sure you do not get overflow in your datatype!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f033127-cb6a-4985-a80e-60eb00fa69e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsharp_image = np.float32(cv2.imread('img/unsharp.png'))\n",
    "\n",
    "# Blur the image\n",
    "unsharp_image_float = unsharp_image.astype(np.float32)\n",
    "blurred_image = cv2.GaussianBlur(unsharp_image_float, (7, 7), 4)\n",
    "\n",
    "# Subtract the blurred from the original\n",
    "difference_image = unsharp_image_float - blurred_image\n",
    "\n",
    "# Amplify the difference by multiplying it with a factor\n",
    "amplified_difference = difference_image * 1.5\n",
    "\n",
    "# Add this amplified difference image to the original image\n",
    "sharpened_image = unsharp_image_float + amplified_difference\n",
    "\n",
    "sharpened_image = np.clip(sharpened_image, 0, 255).astype(np.uint8)\n",
    "sharpened_image = add_name_to_image(sharpened_image)\n",
    "cv2.imwrite('out/assignement12.jpg', sharpened_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5f9c6-89a3-4c6e-bb61-25f98091275c",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement12.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e6c605-4f02-4fe0-aa0e-1430f56681fb",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "#### Assignment 13\n",
    "> Write a program that blurs blots.png diagonally with the kernel below (mind the multiplication factor in front)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfee4a14-e628-41ee-b8ab-c2715b3409d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"img/blots.png\")\n",
    "\n",
    "kernel = (1/7) * np.eye(7, dtype=np.float32)\n",
    "blurred_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "blurred_image = add_name_to_image(blurred_image)\n",
    "cv2.imwrite(\"out/assignement13.jpg\", blurred_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e13638-216c-47ad-8297-ccc6c79d895b",
   "metadata": {},
   "source": [
    "![alt text](./out/assignement13.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b50528-22f0-42ce-950f-d5ee8913e87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
